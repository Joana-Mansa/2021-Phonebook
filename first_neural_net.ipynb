{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_neural_net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM7//c4w7PxTresN4qnlU/p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joana-Mansa/2021-Phonebook/blob/master/first_neural_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGB7W1xfOYUm"
      },
      "source": [
        "# FIRST NEURAL NETWORK (using Numpy)\n",
        "\n",
        "Building Neural Networks from scratch in 9 steps\n",
        "\n",
        "Data Pre-processing(1-4)\n",
        "1. Initialisation (import the libraries)\n",
        "2.  Data generation\n",
        "3. train-test splitting\n",
        "4. Data standardization\n",
        "5. Neural network construction\n",
        "6. Forward Propagation\n",
        "7. Back-Propagation\n",
        "8. Iterative optimisation\n",
        "9. Testing\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5odX6ZtoQwbg"
      },
      "source": [
        "# Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHxJja48Sjpj"
      },
      "source": [
        "# 1. Initialising"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVw4HyqwQ5ki"
      },
      "source": [
        "#Initialization\n",
        "import numpy as np\n",
        "np.random.seed(42) #allows numpy to generate the pseudo numbers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeVQsjG-SQQD"
      },
      "source": [
        "# 2. Generating the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMBJ71UJSZt2",
        "outputId": "6731f329-a3a1-40e4-87c8-78e5df034739"
      },
      "source": [
        "X_num_row, X_num_col = [2,10000] \n",
        "# row represents the number of features, columns represents datum points\n",
        "X_raw = np.random.rand(X_num_row, X_num_col) *100\n",
        "X_raw"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[72.9998311 , 18.45119956, 34.66396944, ...,  1.94558628,\n",
              "        40.10048425, 25.73979791],\n",
              "       [63.81445684, 45.92924535, 96.44985249, ..., 26.95694318,\n",
              "        43.43197722, 48.74236985]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlRNcgngTZ_q",
        "outputId": "2bbe4410-6806-4c6f-8c36-1f0cfc85ff5b"
      },
      "source": [
        "y_raw = np.concatenate(([(X_raw[0,:] + X_raw[1,:])], [(X_raw[0,:] - X_raw[1,:])], np.abs([(X_raw[0,:]- X_raw[1,:])])))\n",
        "\n",
        "#for input a and b, output is a+b, a-b and |a-b|\n",
        "y_num_row, y_num_col = y_raw.shape\n",
        "y_raw.shape\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDEVE3-7W6RO"
      },
      "source": [
        "# 3. Splitting train-test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDDCsTbnWMtp"
      },
      "source": [
        "train_ratio = 0.7\n",
        "num_train_datum = int(train_ratio*X_num_col)\n",
        "X_raw_train = X_raw[:,0:num_train_datum]\n",
        "X_raw_test = X_raw[:,num_train_datum:]\n",
        "\n",
        "y_raw_train = y_raw[:,0:num_train_datum]\n",
        "y_raw_test = y_raw[:,num_train_datum:]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljq2FFYgYDar"
      },
      "source": [
        "## 4. Standardize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdjRxYYCYAoZ"
      },
      "source": [
        "class scaler:\n",
        "  def __init__(self, mean, std):\n",
        "    self.mean = mean\n",
        "    self.std = std\n",
        "\n",
        "def get_scaler(row):\n",
        "  mean = np.mean(row)\n",
        "  std = np.std(row)\n",
        "  return scaler (mean, std)\n",
        "\n",
        "def standardize(data, scaler):\n",
        "  return (data - scaler.mean)/ scaler.std\n",
        "\n",
        "def unstandardize(data, scaler):\n",
        "  return (data * scaler.std) + scaler.mean"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj3ZXSo_Y_0k"
      },
      "source": [
        "# Construct scalers from training set\n",
        "\n",
        "X_scalers = [get_scaler(X_raw_train[row,:]) for row in range(X_num_row)]\n",
        "X_train = np.array([standardize(X_raw_train[row,:], X_scalers[row]) for row in range(X_num_row)])\n",
        "\n",
        "y_scalers = [get_scaler(y_raw_train[row,:]) for row in range(y_num_row)]\n",
        "y_train = np.array([standardize(y_raw_train[row,:], y_scalers[row]) for row in range(y_num_row)])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQjfDxfv8gtv"
      },
      "source": [
        "# apply those scalers to testing set\n",
        "\n",
        "X_test = np.array([standardize(X_raw_test[row,:], X_scalers[row]) for row in range(X_num_row)])\n",
        "y_test = np.array([standardize(y_raw_test[row,:], y_scalers[row]) for row in range(y_num_row)])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnky9NRoalyP",
        "outputId": "e2f86be8-788b-4c4a-987b-3ff9daa814c2"
      },
      "source": [
        "#check if data has been standardised \n",
        "\n",
        "print([X_train[row,:].mean() for row in range(X_num_row)]) #should be close to 0\n",
        "print([X_train[row,:].std() for row in range(X_num_row)]) #should be close to 1\n",
        "\n",
        "print([y_train[row,:].mean() for row in range(y_num_row)]) #should be close to 0\n",
        "print([y_train[row,:].std() for row in range(y_num_row)]) # should be close to 1"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.6240976817373719e-16, -6.293378516732316e-17]\n",
            "[1.0, 0.9999999999999999]\n",
            "[1.4210854715202004e-17, -5.075305255429287e-18, -6.496390726949488e-17]\n",
            "[1.0, 1.0, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8yKZDd4ghBg"
      },
      "source": [
        "# 5. Constructing a neural net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc8q7uj9f0f5"
      },
      "source": [
        "class layer:\n",
        "  def __init__(self, layer_index, is_output, input_dim, output_dim, activation):\n",
        "    self.layer_index = layer_index #0 indicates input layer\n",
        "    self.is_output = is_output #true indicates output layers, false otherwise\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.activation = activation\n",
        "\n",
        "    #the multiplication constant is sort of arbitrary\n",
        "    if layer_index !=0:\n",
        "      self.W = np.random.randn(output_dim, input_dim) * np.sqrt(2/input_dim)\n",
        "      self.b = np.random.randn(output_dim,1)* np.sqrt(2/input_dim)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37CF-aZpionZ"
      },
      "source": [
        "# change layers_dim to configure your own neural net!\n",
        "layers_dim = [X_num_row, 4, 4, y_num_row] # input layer ---hidden layer --- output layers\n",
        "neural_net = []\n",
        "\n",
        "#construct the net layer\n",
        "for layer_index in range(len(layers_dim)):\n",
        "  if layer_index == 0: #if input layer\n",
        "    neural_net.append(layer(layer_index, False, 0, layers_dim[layer_index], 'irrelevant'))\n",
        "  elif layer_index+1 == len(layers_dim): #if output layer\n",
        "    neural_net.append(layer(layer_index, True, layers_dim[layer_index-1], layers_dim[layer_index], activation='linear'))\n",
        "  else:\n",
        "    neural_net.append(layer(layer_index, False, layers_dim[layer_index-1], layers_dim[layer_index], activation='relu'))\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nqjjVwKmS3h",
        "outputId": "492808d7-031d-4a2e-9a26-c9d1985699bb"
      },
      "source": [
        "#simple check on overfitting\n",
        "\n",
        "\n",
        "pred_n_param = sum([(layers_dim[layer_index]+1)*layers_dim[layer_index+1] for layer_index in range(len(layers_dim)-1)])\n",
        "act_n_param = sum([neural_net[layer_index].W.size + neural_net[layer_index].b.size for layer_index in range(1, len(layers_dim))])\n",
        "print(f'Predicted number of hyperparameters: {pred_n_param}')\n",
        "print(f'Actual number of hyperparameters: {act_n_param}')\n",
        "print(f'Number of data: {X_num_col}')\n",
        "\n",
        "if act_n_param >= X_num_col:\n",
        "  raise Exception('It will overfit')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted number of hyperparameters: 47\n",
            "Actual number of hyperparameters: 47\n",
            "Number of data: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYsyHKGMpZW5"
      },
      "source": [
        "# 6. Performing Forward propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-VyFpFSmavL"
      },
      "source": [
        "def activation(input_, act_func):\n",
        "  if act_func == 'relu':\n",
        "    return np.maximum(input_, np.zeros(input_.shape))\n",
        "  elif act_func == 'linear':\n",
        "    return input_\n",
        "  else:\n",
        "    raise Exception('Activation function is not defined.')"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmzL_I0PqNO7"
      },
      "source": [
        "def forward_prop(input_vec, layers_dim=layers_dim, neural_net=neural_net):\n",
        "  neural_net[0].A = input_vec #Define A in input layer for for-loop convenience\n",
        "  for layer_index in range(1,len(layers_dim)):\n",
        "    neural_net[layer_index].Z = np.add(np.dot(neural_net[layer_index].W, neural_net[layer_index-1].A), neural_net[layer_index].b)\n",
        "    neural_net[layer_index].A = activation(neural_net[layer_index].Z, neural_net[layer_index].activation)\n",
        "  return neural_net[layer_index].A"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X70N8I-hs733",
        "outputId": "c81feb5f-1dc9-4218-9efe-a6e08efc3d6c"
      },
      "source": [
        "#test run\n",
        "forward_prop(X_train).shape == y_train.shape #should be true"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZkPHSd-tQt6"
      },
      "source": [
        "# 7. Perform back propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ5OgcbHtOkp"
      },
      "source": [
        "def get_loss(y, y_hat, metric='mse'):\n",
        "    if metric == 'mse':\n",
        "        individual_loss = 0.5 * (y_hat - y) ** 2\n",
        "        return np.mean([np.linalg.norm(individual_loss[:,col], 2) for col in range(individual_loss.shape[1])])\n",
        "    else:\n",
        "        raise Exception('Loss metric is not defined.')\n",
        "\n",
        "def get_dZ_from_loss(y, y_hat, metric):\n",
        "    if metric == 'mse':\n",
        "        return y_hat - y\n",
        "    else:\n",
        "        raise Exception('Loss metric is not defined.')\n",
        "\n",
        "def get_dactivation(A, act_func):\n",
        "    if act_func == 'relu':\n",
        "        return np.maximum(np.sign(A), np.zeros(A.shape)) # 1 if backward input >0, 0 otherwise; then diaganolize\n",
        "    elif act_func == 'linear':\n",
        "        return np.ones(A.shape)\n",
        "    else:\n",
        "        raise Exception('Activation function is not defined.')"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11rAMmhNvDWv"
      },
      "source": [
        "def backward_prop(y, y_hat, metric='mse', layers_dim=layers_dim, neural_net=neural_net, num_train_datum=num_train_datum):\n",
        "    for layer_index in range(len(layers_dim)-1,0,-1):\n",
        "        if layer_index+1 == len(layers_dim): # if output layer\n",
        "            dZ = get_dZ_from_loss(y, y_hat, metric)\n",
        "        else: \n",
        "            dZ = np.multiply(np.dot(neural_net[layer_index+1].W.T, dZ), \n",
        "                             get_dactivation(neural_net[layer_index].A, neural_net[layer_index].activation))\n",
        "        dW = np.dot(dZ, neural_net[layer_index-1].A.T) / num_train_datum\n",
        "        db = np.sum(dZ, axis=1, keepdims=True) / num_train_datum\n",
        "        \n",
        "        neural_net[layer_index].dW = dW\n",
        "        neural_net[layer_index].db = db"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X3pGcu_xyvi"
      },
      "source": [
        "# 8. Optimize Iteratively (Gradient Descent)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yz1aWSRxwO0",
        "outputId": "876bd17c-0749-422c-cfb3-ceb0a28a1afd"
      },
      "source": [
        "learning_rate = 0.01\n",
        "max_epoch = 1000000\n",
        "\n",
        "for epoch in range(1,max_epoch+1):\n",
        "    y_hat_train = forward_prop(X_train) # update y_hat\n",
        "    backward_prop(y_train, y_hat_train) # update (dW,db)\n",
        "    \n",
        "    for layer_index in range(1,len(layers_dim)):        # update (W,b)\n",
        "        neural_net[layer_index].W = neural_net[layer_index].W - learning_rate * neural_net[layer_index].dW\n",
        "        neural_net[layer_index].b = neural_net[layer_index].b - learning_rate * neural_net[layer_index].db\n",
        "    \n",
        "    if epoch % 100000 == 0:\n",
        "        print(f'{get_loss(y_train, y_hat_train):.4f}')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3360\n",
            "0.3349\n",
            "0.3349\n",
            "0.3349\n",
            "0.3349\n",
            "0.3349\n",
            "0.3349\n",
            "0.3349\n",
            "0.3349\n",
            "0.3349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOlmh-1Ezhag",
        "outputId": "835cfa54-34b1-4dc2-f663-a0adc177c49d"
      },
      "source": [
        "# test loss\n",
        "get_loss(y_test, forward_prop(X_test))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3469461475376623"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv0xqLTr3oVu"
      },
      "source": [
        "def predict(X_raw_any):\n",
        "    X_any = np.array([standardize(X_raw_any[row,:], X_scalers[row]) for row in range(X_num_row)])\n",
        "    y_hat = forward_prop(X_any)\n",
        "    y_hat_any = np.array([unstandardize(y_hat[row,:], y_scalers[row]) for row in range(y_num_row)])\n",
        "    return y_hat_any"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6MY4zKf42_X",
        "outputId": "adbf7499-fa8a-485e-f626-fa8a9df4e03b"
      },
      "source": [
        "predict(np.array([[30,70],[70,30],[3,5],[888,122]]).T)\n",
        "\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[105.90035702,  96.82669242,   4.66089373, 112.74597954],\n",
              "       [-14.31562862,  26.18649919, -16.53548493,  93.73617085],\n",
              "       [ 25.37979978,  47.86301628,  10.27389566,  94.33391677]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzbWviw1HodP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}